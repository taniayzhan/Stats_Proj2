---
title: "tests"
author: "Tina Pai"
date: "4/4/2020"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(caret)
library(GGally)
library(plotROC)
```

```{r datawrangle}
#import data
bank = read.csv("data/bank-additional-full.csv",sep=";")

#downsample
down_size <- downSample(x = bank[, -ncol(bank)], y = bank$y)
colnames(down_size)[21] <- "y"
table(down_size$y)

combos <- combn(c("duration","nr.employed" , "month", "poutcome", "emp.var.rate",
                  "cons.price.idx", "job", "contact", "euribor3m", "default", "day_of_week", 
                         "pdays", "campaign", "cons.conf.idx"), 2, FUN = NULL, simplify = TRUE)
combos[,1]
n = length(combos[1,])
var_1 = c()
var_2 = c()
interaction_ps = c()
for(i in 1:n){
  model.main<-glm(y ~ eval(parse(text = combos[1,i])) * eval(parse(text = combos[2,i])), data=down_size,family = binomial(link="logit"))
  s <- summary(model.main)
  var_1 = c(var_1, combos[1,i])
  var_2 = c(var_2, combos[2,i])
  interaction_ps = c(interaction_ps, s$coefficients[4,4])
}
interaction_df = data.frame(var_1, var_2, interaction_ps)
head(interaction_df)
interactions <- interaction_df %>%
  filter(interaction_ps < .0001) %>%
  mutate(var_1 = as.character(var_1)) %>%
  mutate(var_2 = as.character(var_2))
```

```{r}
print(interactions)
```

Interaction Plots

```{r interactionplots}

for(i in 1:dim(interactions)[1]) {

  #barplot of two variables blocked on y/n
  print(bank %>%
    ggplot(aes(y=eval(parse(text = interactions$var_1[i])), x=eval(parse(text = interactions$var_2[i])), color = y)) +
    geom_boxplot()+
    xlab(interactions$var_2[i]) +
    ylab(interactions$var_1[i]) +
    ggtitle("Distribution of ")
  )
  
  #summary of p value of interaction term
  model<-glm(y ~ eval(parse(text=interactions$var_1[i])) * eval(parse(text=interactions$var_2[i])), data=down_size,family = binomial(link="logit"))
  print(summary(model))
}
```

Make model with interaction terms
```{r}
model.interaction1 <- glm(y ~ duration * nr.employed + month + poutcome + emp.var.rate + 
                  cons.price.idx + job + contact + euribor3m + default + day_of_week + 
                  pdays + campaign + cons.conf.idx +
      duration*nr.employed +
      duration*poutcome +
        duration *  emp.var.rate +
        duration * cons.price.idx +
        duration * job +
        duration * euribor3m +
        duration * cons.conf.idx +
     nr.employed * emp.var.rate +
     nr.employed * euribor3m +
    nr.employed * campaign +
    nr.employed * cons.conf.idx +
          month * cons.price.idx +
          month * job +
          month * contact +
          month * default +
          month * campaign +
       poutcome * emp.var.rate +
       poutcome * job +
       poutcome * euribor3m +
       poutcome * pdays +
       poutcome * cons.conf.idx +
   emp.var.rate * euribor3m +
   emp.var.rate * campaign +
   emp.var.rate * cons.conf.idx +
 cons.price.idx * contact +
 cons.price.idx * pdays +
 cons.price.idx * cons.conf.idx +
      euribor3m * campaign +
      euribor3m * cons.conf.idx +
        default * pdays +
        default * campaign +
        default * cons.conf.idx, data=bank, family="binomial")
```

Make functions for cross validation
```{r cv, echo=FALSE}
#--- CROSS VALIDATION SETUP ---

#creates a train test split with upsampling train data for balance
split_train_test <- function(bankdata) {
  # dataset with "no"
  bankdata_no = bankdata[which(bankdata$y=="no"),]
  # dataset with "yes"
  bankdata_yes = bankdata[which(bankdata$y=="yes"),]
  
  splitPerc = .7 #Training / Test split Percentage
  
  # Training / Test split of "no" dataset
  noIndices = sample(1:dim(bankdata_no)[1],round(splitPerc * dim(bankdata_no)[1]))
  train_no = bankdata_no[noIndices,]
  test_no = bankdata_no[-noIndices,]
  
  # Training / Test split of "yes" dataset
  yesIndices = sample(1:dim(bankdata_yes)[1],round(splitPerc * dim(bankdata_yes)[1]))
  train_yes = bankdata_yes[yesIndices,]
  test_yes = bankdata_yes[-yesIndices,]
  
  # Combine training "no" and "yes"
  bank_train = rbind(train_no, train_yes)
  
  # Combine test "no" and "yes"
  bank_test = rbind(test_no, test_yes)
  
  # upsampling training dataset
  bank_train_upsample <- upSample(x = bank_train[, -ncol(bank_train)], y = bank_train$y)
  colnames(bank_train_upsample)[21] <- "y"
  summary(bank_train_upsample$y)
  
  return(list(bank_train_upsample, bank_test))
}

#gives the average accuracy, sensitivity, and specificity over 5 train-test splits
#for logistic regression model
get_test_metrics <- function(data, formula, thresh){
  accuracies <- c()
  sensitivities <- c()
  specificities <- c()
  for(i in 1:2){
    split_data <- split_train_test(data)
    train <- split_data[[1]]
    test <- split_data[[2]]
    
    model <- glm(formula, data=train,family = binomial(link="logit"))
    pred_probs <- predict(model, test, type="response")
    pred_yns <- factor(ifelse(pred_probs>thresh, "yes", "no"))
    
    cm <- confusionMatrix(table(pred_yns, test$y))
    accuracies <- c(accuracies, cm$overall[1])
    sensitivities <- c(sensitivities, cm$byClass[1])
    specificities <- c(specificities, cm$byClass[2])
  }
  acc = mean(accuracies)
  sens = mean(sensitivities)
  specs = mean(specificities)
  result = list(acc, sens, specs)
  names(result) = c("Accuracy", "Sensitivity", "Specificity")
  return(result)
}

```

see thresholds for the model
```{r}
#finding the best threshold for yes/no
thresholds <- seq(0.02, .6, by=.02)
accs <- c()
sens <- c()
specs <- c()
for(i in thresholds){
  print("i", i)
  print(i)
  m <- get_test_metrics(bank, y~duration + nr.employed + month + poutcome + emp.var.rate + 
                                  cons.price.idx + job + contact + euribor3m + default + day_of_week + 
                                  pdays + campaign + cons.conf.idx, i)
  accs <- c(accs, m$Accuracy)
  sens <- c(sens, m$Sensitivity)
  specs <- c(specs, m$Specificity)
}

accs
sens
specs


metrics <- data.frame(thresholds,accs,sens,specs)
metrics_long <- metrics %>%
  gather(key=metric, percent, accs:specs)

#plot the accuracy, sensitivity, and specificity over the thresholds; between .1-.2 seems decent to me
metrics_long %>%
  ggplot(aes(x=thresholds, y=percent, color = metric)) +
  geom_point() +
  ggtitle("Accuracy, Sensitivity, and Specificity at Thresholds")

```


a simple model
```{r}
model.main<-glm(y ~ duration * nr.employed + month + poutcome + emp.var.rate + 
                  cons.price.idx + job + contact + euribor3m + default + day_of_week + 
                  pdays + campaign + cons.conf.idx, data=bank,family = binomial(link="logit"))
```


Compare ROC between complex model vs simple model
```{r}

df <- rbind(data.frame(predictor = predict(model.interaction1, bank),
                       known.truth = bank$y,
                       model = "Complex Model"),
            data.frame(predictor = predict(model.main, bank),
                       known.truth = bank$y,
                       model = "Simple Model"))

ggroc <- ggplot(df, aes(d = known.truth, m = predictor, color = model)) + 
  geom_roc(n.cuts = 0) + geom_abline(intercept = 0, slope = 1, linetype='dashed') 

ggroc
calc_auc(ggroc)
```

